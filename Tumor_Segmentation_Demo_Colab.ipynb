{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHMqPIQ3kf-l"
      },
      "source": [
        "# üß† Brain Tumor Segmentation Using FFT Filters\n",
        "## BME 271D Final Project - Ege √ñzemek, Max Bazan, Sasha Nikiforov\n",
        "\n",
        "### Frequency-Domain Analysis for Medical Image Segmentation\n",
        "\n",
        "**This notebook demonstrates:**\n",
        "- FFT-based tumor segmentation (High-Pass & Band-Pass filters)\n",
        "- Comparison with spatial domain methods (Otsu, Blob detection)\n",
        "- Quantitative evaluation (Dice, IoU, Boundary Accuracy)\n",
        "- Multi-tier confidence scoring for clinical decision support"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSLVmNKDkf-n"
      },
      "source": [
        "---\n",
        "## üìö Project Overview & Motivation\n",
        "\n",
        "### Clinical Context\n",
        "Brain tumor segmentation is a critical step in:\n",
        "- **Surgical Planning**: Precise tumor boundaries guide neurosurgical procedures\n",
        "- **Treatment Monitoring**: Tracking tumor size changes during therapy\n",
        "- **Radiotherapy Planning**: Targeting radiation to tumor while sparing healthy tissue\n",
        "- **Diagnostic Workflow**: Reducing radiologist workload through automation\n",
        "\n",
        "### Why Frequency-Domain Methods?\n",
        "Traditional spatial-domain segmentation (like Otsu thresholding) works well on high-contrast images but struggles with:\n",
        "- **Complex texture patterns** within tumors\n",
        "- **Subtle intensity variations** between tumor and healthy tissue\n",
        "- **Noise and artifacts** in medical imaging\n",
        "\n",
        "**Fourier Transform** decomposes images into frequency components:\n",
        "- **Low frequencies** = smooth backgrounds, large structures\n",
        "- **High frequencies** = edges, boundaries, fine details\n",
        "- **Mid frequencies** = texture patterns\n",
        "\n",
        "By filtering in the frequency domain, we can:\n",
        "\n",
        "‚úÖ **Emphasize tumor boundaries** (high-pass filtering)  \n",
        "‚úÖ **Isolate tumor texture** (band-pass filtering)  \n",
        "‚úÖ **Suppress background noise** (complementary filtering)\n",
        "\n",
        "### Course Concepts Applied (BME 271D)\n",
        "This project demonstrates key concepts from Signals & Systems:\n",
        "1. **2D Fourier Transform**: Extending 1D FFT to images\n",
        "2. **Filter Design**: High-pass, band-pass, and low-pass filters\n",
        "3. **Frequency Response**: Understanding how filters affect different frequency components\n",
        "4. **Convolution**: Morphological operations as convolution with structuring elements\n",
        "5. **System Analysis**: Comparing multiple methods quantitatively\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Workflow Summary\n",
        "\n",
        "```\n",
        "1. Upload MRI Image ‚Üí Load and normalize to [0,1]\n",
        "2. Upload Ground Truth (Optional) ‚Üí For quantitative evaluation\n",
        "3. FFT Analysis ‚Üí Visualize frequency spectrum\n",
        "4. Apply Filters ‚Üí High-pass, Band-pass, Combined\n",
        "5. Segment Tumor ‚Üí 6 different methods\n",
        "6. Calculate Metrics ‚Üí Dice, IoU, Boundary Accuracy\n",
        "7. Generate Report ‚Üí Clinical confidence scoring\n",
        "```\n",
        "\n",
        "**Expected Runtime**: 2-5 minutes per image\n",
        "\n",
        "**Best Results With**: T1-weighted contrast-enhanced MRI (bright tumors work best)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bmNpSN7kf-n"
      },
      "source": [
        "## üîß Setup: Installation & Imports\n",
        "\n",
        "This cell installs all required packages and imports the necessary libraries.\n",
        "\n",
        "**Key Libraries:**\n",
        "- `numpy`: Numerical operations and array handling\n",
        "- `scipy`: FFT computation and signal processing\n",
        "- `scikit-image`: Image processing and morphological operations\n",
        "- `matplotlib`: Visualization\n",
        "- `pandas`: Data organization for metrics\n",
        "\n",
        "**Custom Module:**\n",
        "- `tumor_segmentation.py`: Contains core FFT filtering functions developed for this project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUvpTqZskf-o"
      },
      "outputs": [],
      "source": [
        "# ========== INSTALLATION & IMPORTS ==========\n",
        "!pip install -q numpy matplotlib scipy scikit-image pandas\n",
        "!wget -q https://raw.githubusercontent.com/egeozemek/tumor-segmentation/main/tumor_segmentation.py\n",
        "\n",
        "import tumor_segmentation as ts\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image as PILImage\n",
        "from google.colab import files\n",
        "from scipy import ndimage\n",
        "from scipy.spatial import distance\n",
        "from skimage.filters import threshold_otsu\n",
        "from skimage.measure import label, regionprops\n",
        "from skimage.morphology import remove_small_objects, binary_closing, binary_opening, binary_dilation, disk, erosion\n",
        "from skimage.segmentation import find_boundaries\n",
        "\n",
        "print('‚úÖ Setup complete!')\n",
        "\n",
        "# ========== HELPER FUNCTIONS ==========\n",
        "\n",
        "def load_image_safe(filepath):\n",
        "    \"\"\"Load image and convert to grayscale float [0,1]\"\"\"\n",
        "    img = PILImage.open(filepath).convert('L')\n",
        "    arr = np.array(img).astype(np.float64) / 255.0\n",
        "    return arr\n",
        "\n",
        "def load_mask_safe(filepath):\n",
        "    \"\"\"Load mask and convert to binary [0,1]\"\"\"\n",
        "    img = PILImage.open(filepath).convert('L')\n",
        "    arr = np.array(img)\n",
        "    # Convert from 0-255 to 0-1\n",
        "    return (arr > 127).astype(np.float32)\n",
        "\n",
        "def remove_peripheral(mask, image, border_frac=0.12):\n",
        "    \"\"\"Remove skull and peripheral structures from segmentation.\"\"\"\n",
        "    h, w = mask.shape\n",
        "    border_h, border_w = int(h * border_frac), int(w * border_frac)\n",
        "\n",
        "    # Define internal region (excluding borders)\n",
        "    internal = np.zeros_like(mask, dtype=bool)\n",
        "    internal[border_h:-border_h, border_w:-border_w] = True\n",
        "\n",
        "    # Filter regions\n",
        "    labeled = label(mask)\n",
        "    cleaned = np.zeros_like(mask, dtype=bool)\n",
        "\n",
        "    for region in regionprops(labeled):\n",
        "        region_pixels = (labeled == region.label)\n",
        "        internal_pixels = np.logical_and(region_pixels, internal).sum()\n",
        "\n",
        "        # Region must be >60% internal (not on border)\n",
        "        if internal_pixels / region.area > 0.6:\n",
        "            cleaned[region_pixels] = True\n",
        "\n",
        "    return cleaned\n",
        "\n",
        "# ========== SEGMENTATION METHODS ==========\n",
        "\n",
        "def otsu_baseline(image):\n",
        "    \"\"\"Otsu thresholding baseline method.\"\"\"\n",
        "    try:\n",
        "        thresh = threshold_otsu(image)\n",
        "        mask = image > thresh\n",
        "        mask = binary_closing(mask, disk(2))\n",
        "        mask = remove_small_objects(mask, min_size=100)\n",
        "        mask = remove_peripheral(mask, image)\n",
        "        return mask.astype(np.float32)\n",
        "    except:\n",
        "        return np.zeros_like(image, dtype=np.float32)\n",
        "\n",
        "def fft_highpass(image, sensitivity=0.5):\n",
        "    \"\"\"FFT High-Pass filter segmentation.\"\"\"\n",
        "    try:\n",
        "        mean_val, std_val = image.mean(), image.std()\n",
        "\n",
        "        # Apply high-pass filter\n",
        "        hp_img, _, _ = ts.filter_pipeline(image, 'hp', cutoff_radius=25)\n",
        "        hp_img = (hp_img - hp_img.min()) / (hp_img.max() - hp_img.min() + 1e-8)\n",
        "\n",
        "        # Threshold\n",
        "        hp_mask = hp_img > np.percentile(hp_img, 87 - sensitivity * 7)\n",
        "\n",
        "        # Must be bright in original\n",
        "        hp_mask = np.logical_and(hp_mask, image > mean_val + 0.5 * std_val)\n",
        "\n",
        "        # Morphological cleanup\n",
        "        hp_mask = binary_closing(hp_mask, disk(2))\n",
        "        hp_mask = remove_small_objects(hp_mask, min_size=80)\n",
        "        hp_mask = remove_peripheral(hp_mask, image)\n",
        "\n",
        "        return hp_mask.astype(np.float32)\n",
        "    except:\n",
        "        return np.zeros_like(image, dtype=np.float32)\n",
        "\n",
        "def fft_bandpass(image, sensitivity=0.5):\n",
        "    \"\"\"FFT Band-Pass filter segmentation.\"\"\"\n",
        "    try:\n",
        "        mean_val, std_val = image.mean(), image.std()\n",
        "\n",
        "        # Apply band-pass filter\n",
        "        bp_img, _, _ = ts.filter_pipeline(image, 'bp', r1=10, r2=50)\n",
        "        bp_img = (bp_img - bp_img.min()) / (bp_img.max() - bp_img.min() + 1e-8)\n",
        "\n",
        "        # Threshold\n",
        "        bp_mask = bp_img > np.percentile(bp_img, 83 - sensitivity * 7)\n",
        "\n",
        "        # Must be bright in original\n",
        "        bp_mask = np.logical_and(bp_mask, image > mean_val + 0.5 * std_val)\n",
        "\n",
        "        # Morphological cleanup\n",
        "        bp_mask = binary_closing(bp_mask, disk(2))\n",
        "        bp_mask = remove_small_objects(bp_mask, min_size=80)\n",
        "        bp_mask = remove_peripheral(bp_mask, image)\n",
        "\n",
        "        return bp_mask.astype(np.float32)\n",
        "    except:\n",
        "        return np.zeros_like(image, dtype=np.float32)\n",
        "\n",
        "def fft_combined(image, sensitivity=0.5):\n",
        "    \"\"\"Combined FFT method (OR of high-pass and band-pass).\"\"\"\n",
        "    hp = fft_highpass(image, sensitivity)\n",
        "    bp = fft_bandpass(image, sensitivity)\n",
        "    combined = np.logical_or(hp, bp).astype(np.float32)\n",
        "    return combined\n",
        "\n",
        "def blob_detection(image, sensitivity=0.5):\n",
        "    \"\"\"Blob detection for bright tumor masses.\"\"\"\n",
        "    try:\n",
        "        h, w = image.shape\n",
        "        mean_val, std_val = image.mean(), image.std()\n",
        "\n",
        "        # Find very bright regions\n",
        "        bright_thresh = mean_val + (2.2 - sensitivity * 0.4) * std_val\n",
        "        percentile_thresh = np.percentile(image, 92 - sensitivity * 5)\n",
        "\n",
        "        blob_mask = np.logical_and(image > bright_thresh, image > percentile_thresh)\n",
        "\n",
        "        # Morphological operations\n",
        "        blob_mask = binary_opening(blob_mask, disk(2))\n",
        "        blob_mask = binary_closing(blob_mask, disk(3))\n",
        "        blob_mask = remove_small_objects(blob_mask, min_size=120)\n",
        "        blob_mask = remove_peripheral(blob_mask, image)\n",
        "\n",
        "        # Shape filtering\n",
        "        labeled = label(blob_mask)\n",
        "        filtered = np.zeros_like(blob_mask)\n",
        "\n",
        "        for region in regionprops(labeled, intensity_image=image):\n",
        "            # Size constraints\n",
        "            if region.area < 100 or region.area > h * w * 0.25:\n",
        "                continue\n",
        "\n",
        "            # Shape constraints\n",
        "            circularity = 4 * np.pi * region.area / (region.perimeter ** 2 + 1e-8)\n",
        "            if circularity < 0.12:\n",
        "                continue\n",
        "            if region.solidity < 0.65:\n",
        "                continue\n",
        "\n",
        "            # Intensity constraint\n",
        "            if region.mean_intensity < mean_val + std_val:\n",
        "                continue\n",
        "\n",
        "            filtered[labeled == region.label] = True\n",
        "\n",
        "        return filtered.astype(np.float32)\n",
        "    except:\n",
        "        return np.zeros_like(image, dtype=np.float32)\n",
        "\n",
        "def hybrid_combined(image, sensitivity=0.5):\n",
        "    \"\"\"Hybrid ensemble combining FFT and blob detection.\"\"\"\n",
        "    fft_comb = fft_combined(image, sensitivity)\n",
        "    blob = blob_detection(image, sensitivity)\n",
        "\n",
        "    # Voting: FFT gets 1.5 votes, Blob gets 1 vote\n",
        "    vote_map = fft_comb * 1.5 + blob * 1.0\n",
        "\n",
        "    # Need 1.0+ votes (any single method can trigger)\n",
        "    combined = (vote_map >= (1.0 - sensitivity * 0.1)).astype(np.float32)\n",
        "\n",
        "    # Final cleanup\n",
        "    combined = binary_closing(combined.astype(bool), disk(2))\n",
        "    combined = remove_small_objects(combined, min_size=100)\n",
        "\n",
        "    # Shape filter\n",
        "    labeled = label(combined)\n",
        "    final = np.zeros_like(combined)\n",
        "\n",
        "    for region in regionprops(labeled):\n",
        "        if region.eccentricity > 0.96 or region.solidity < 0.65:\n",
        "            continue\n",
        "        final[labeled == region.label] = True\n",
        "\n",
        "    return final.astype(np.float32)\n",
        "\n",
        "# ========== ANALYSIS FUNCTIONS ==========\n",
        "\n",
        "def get_tumor_center(mask):\n",
        "    \"\"\"Get tumor center using largest connected component centroid.\"\"\"\n",
        "    if mask.sum() == 0:\n",
        "        return None\n",
        "\n",
        "    # Find largest connected component\n",
        "    labeled = label(mask)\n",
        "    regions = regionprops(labeled)\n",
        "\n",
        "    if len(regions) == 0:\n",
        "        return None\n",
        "\n",
        "    # Get centroid of largest region\n",
        "    largest = max(regions, key=lambda x: x.area)\n",
        "    centroid = largest.centroid  # (row, col)\n",
        "\n",
        "    return (int(centroid[0]), int(centroid[1]))\n",
        "\n",
        "def calculate_confidence(image, mask):\n",
        "    \"\"\"Calculate detection confidence with 3-tier system.\"\"\"\n",
        "    h, w = image.shape\n",
        "    total = h * w\n",
        "    tumor_px = mask.sum()\n",
        "    area_pct = (tumor_px / total) * 100\n",
        "\n",
        "    # No detection if too small\n",
        "    if tumor_px < total * 0.003:  # <0.3%\n",
        "        return 0.0, 'NONE'\n",
        "\n",
        "    labeled = label(mask)\n",
        "    regions = regionprops(labeled, intensity_image=image)\n",
        "\n",
        "    if len(regions) == 0:\n",
        "        return 0.0, 'NONE'\n",
        "\n",
        "    largest = max(regions, key=lambda x: x.area)\n",
        "\n",
        "    # Size score\n",
        "    if 0.4 <= area_pct <= 12:\n",
        "        size_score = 1.0\n",
        "    elif area_pct < 0.4:\n",
        "        size_score = area_pct / 0.4\n",
        "    else:\n",
        "        size_score = max(0, 1 - (area_pct - 12) / 18)\n",
        "\n",
        "    # Shape score\n",
        "    circularity = 4 * np.pi * largest.area / (largest.perimeter ** 2 + 1e-8)\n",
        "    shape_score = min(circularity * 2.5, 1.0)\n",
        "\n",
        "    # Contrast score\n",
        "    tumor_int = image[mask > 0].mean()\n",
        "    bg_int = image[mask == 0].mean() if (mask == 0).any() else 0\n",
        "    contrast_score = min(max((tumor_int - bg_int) * 4, 0), 1.0)\n",
        "\n",
        "    # Overall confidence\n",
        "    confidence = size_score * 0.3 + shape_score * 0.3 + contrast_score * 0.4\n",
        "    confidence = np.clip(confidence, 0, 1)\n",
        "\n",
        "    # Determine tier\n",
        "    if confidence >= 0.65:\n",
        "        tier = 'HIGH'\n",
        "    elif confidence >= 0.35:\n",
        "        tier = 'MODERATE'\n",
        "    elif confidence >= 0.20:\n",
        "        tier = 'LOW'\n",
        "    else:\n",
        "        tier = 'NONE'\n",
        "\n",
        "    return confidence, tier\n",
        "\n",
        "# ========== QUANTITATIVE METRICS ==========\n",
        "\n",
        "def dice_coefficient(pred, true):\n",
        "    \"\"\"Calculate Dice Similarity Coefficient.\"\"\"\n",
        "    pred = (pred > 0.5).astype(np.float32)\n",
        "    true = (true > 0.5).astype(np.float32)\n",
        "\n",
        "    intersection = np.sum(pred * true)\n",
        "    pred_sum = np.sum(pred)\n",
        "    true_sum = np.sum(true)\n",
        "\n",
        "    if pred_sum + true_sum == 0:\n",
        "        return 1.0  # Both empty\n",
        "\n",
        "    dice = (2.0 * intersection) / (pred_sum + true_sum)\n",
        "    return dice\n",
        "\n",
        "def iou_score(pred, true):\n",
        "    \"\"\"Calculate Intersection over Union.\"\"\"\n",
        "    pred = (pred > 0.5).astype(np.float32)\n",
        "    true = (true > 0.5).astype(np.float32)\n",
        "\n",
        "    intersection = np.sum(pred * true)\n",
        "    union = np.sum(np.logical_or(pred, true))\n",
        "\n",
        "    if union == 0:\n",
        "        return 1.0  # Both empty\n",
        "\n",
        "    iou = intersection / union\n",
        "    return iou\n",
        "\n",
        "def boundary_accuracy(pred, true, tolerance=2):\n",
        "    \"\"\"Calculate boundary accuracy within tolerance (pixels).\"\"\"\n",
        "    pred = (pred > 0.5).astype(bool)\n",
        "    true = (true > 0.5).astype(bool)\n",
        "\n",
        "    # Find boundaries\n",
        "    pred_boundary = find_boundaries(pred, mode='inner')\n",
        "    true_boundary = find_boundaries(true, mode='inner')\n",
        "\n",
        "    if not pred_boundary.any() or not true_boundary.any():\n",
        "        return 0.0\n",
        "\n",
        "    # Get boundary coordinates\n",
        "    pred_coords = np.argwhere(pred_boundary)\n",
        "    true_coords = np.argwhere(true_boundary)\n",
        "\n",
        "    if len(pred_coords) == 0 or len(true_coords) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    # For each predicted boundary pixel, find distance to nearest true boundary pixel\n",
        "    distances = distance.cdist(pred_coords, true_coords, metric='euclidean')\n",
        "    min_distances = distances.min(axis=1)\n",
        "\n",
        "    # Calculate percentage within tolerance\n",
        "    within_tolerance = (min_distances <= tolerance).sum()\n",
        "    accuracy = within_tolerance / len(pred_coords)\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "def evaluate_all_methods(image, ground_truth, sensitivity=0.5):\n",
        "    \"\"\"Evaluate all segmentation methods against ground truth.\"\"\"\n",
        "    methods = {\n",
        "        'Otsu Baseline': otsu_baseline(image),\n",
        "        'FFT High-Pass': fft_highpass(image, sensitivity),\n",
        "        'FFT Band-Pass': fft_bandpass(image, sensitivity),\n",
        "        'FFT Combined': fft_combined(image, sensitivity),\n",
        "        'Blob Detection': blob_detection(image, sensitivity),\n",
        "        'Hybrid Combined': hybrid_combined(image, sensitivity)\n",
        "    }\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for method_name, pred_mask in methods.items():\n",
        "        dice = dice_coefficient(pred_mask, ground_truth)\n",
        "        iou = iou_score(pred_mask, ground_truth)\n",
        "        boundary_acc = boundary_accuracy(pred_mask, ground_truth, tolerance=2)\n",
        "\n",
        "        results.append({\n",
        "            'Method': method_name,\n",
        "            'Dice': dice,\n",
        "            'IoU': iou,\n",
        "            'Boundary Accuracy': boundary_acc\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results), methods\n",
        "\n",
        "# Initialize variables\n",
        "mri_image = None\n",
        "ground_truth_mask = None\n",
        "\n",
        "print('\\n‚úÖ All functions loaded successfully!')\n",
        "print('üìã Ready to process images!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKlfzRCkkf-p"
      },
      "source": [
        "---\n",
        "## üì§ Step 1: Upload MRI Image (REQUIRED)\n",
        "\n",
        "Upload your brain MRI scan here.\n",
        "\n",
        "### Image Requirements:\n",
        "- **Format**: JPEG, PNG, or other common image formats\n",
        "- **Modality**: Works best with T1-weighted contrast-enhanced MRI\n",
        "- **Quality**: Higher resolution = better results\n",
        "- **Content**: Should show axial brain slice with visible tumor\n",
        "\n",
        "### What Happens:\n",
        "1. Image is loaded and converted to grayscale\n",
        "2. Pixel values are normalized to [0, 1] range\n",
        "3. Image is displayed for verification\n",
        "\n",
        "**Note**: This is the only required upload. The ground truth mask (Step 2) is optional."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koQMjr8ukf-p"
      },
      "outputs": [],
      "source": [
        "# Upload MRI Image\n",
        "print('üì§ Please upload your MRI image...')\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    mri_image = load_image_safe(filename)\n",
        "\n",
        "    print(f'\\n‚úÖ MRI Image loaded: {filename}')\n",
        "    print(f'   Size: {mri_image.shape}')\n",
        "    print(f'   Range: [{mri_image.min():.3f}, {mri_image.max():.3f}]')\n",
        "\n",
        "    # Display\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(mri_image, cmap='gray')\n",
        "    plt.title('Uploaded MRI Image', fontsize=14, fontweight='bold')\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print('‚ùå No image uploaded!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwhEN82_kf-p"
      },
      "source": [
        "---\n",
        "## üì§ Step 2: Upload Ground Truth Mask (OPTIONAL)\n",
        "\n",
        "**Skip this step if you don't have a ground truth mask.**\n",
        "\n",
        "If you have a mask, upload it here to get quantitative evaluation metrics.\n",
        "\n",
        "### Mask Requirements:\n",
        "- **Format**: PNG (binary mask)\n",
        "- **Size**: Must exactly match MRI image dimensions\n",
        "- **Values**:\n",
        "  - White (255) = Tumor region\n",
        "  - Black (0) = Background\n",
        "- **Purpose**: Enables calculation of Dice, IoU, and Boundary Accuracy\n",
        "\n",
        "### What You Get With a Mask:\n",
        "‚úÖ **Quantitative Metrics**: Dice coefficient, IoU, Boundary accuracy  \n",
        "‚úÖ **Method Comparison**: Bar plots showing which methods perform best  \n",
        "‚úÖ **Performance Analysis**: Statistical comparison to Otsu baseline\n",
        "\n",
        "### What You Get Without a Mask:\n",
        "- Visual segmentation results\n",
        "- Confidence scores\n",
        "- Tumor localization (green cross)\n",
        "- Clinical report\n",
        "\n",
        "**Note**: For testing purposes, you can skip this and still see all detection results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNCqqi8Zkf-p"
      },
      "outputs": [],
      "source": [
        "# Upload Ground Truth Mask (Optional)\n",
        "print('üì§ Upload ground truth mask (or skip if you don\\'t have one)...')\n",
        "uploaded_mask = files.upload()\n",
        "\n",
        "if uploaded_mask:\n",
        "    mask_filename = list(uploaded_mask.keys())[0]\n",
        "    ground_truth_mask = load_mask_safe(mask_filename)\n",
        "\n",
        "    print(f'\\n‚úÖ Ground Truth Mask loaded: {mask_filename}')\n",
        "    print(f'   Size: {ground_truth_mask.shape}')\n",
        "    print(f'   Unique values: {np.unique(ground_truth_mask)}')\n",
        "    print(f'   Tumor coverage: {ground_truth_mask.sum() / ground_truth_mask.size * 100:.2f}%')\n",
        "\n",
        "    # Display\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    axes[0].imshow(mri_image, cmap='gray')\n",
        "    axes[0].set_title('MRI Image', fontsize=12)\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    axes[1].imshow(ground_truth_mask, cmap='gray')\n",
        "    axes[1].set_title('Ground Truth Mask', fontsize=12)\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    axes[2].imshow(mri_image, cmap='gray')\n",
        "    axes[2].imshow(ground_truth_mask, cmap='Reds', alpha=0.5)\n",
        "    axes[2].set_title('Overlay', fontsize=12)\n",
        "    axes[2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    ground_truth_mask = None\n",
        "    print('\\n‚ÑπÔ∏è  No mask uploaded - will skip quantitative evaluation.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46uTyfBBkf-p"
      },
      "source": [
        "---\n",
        "## üî¨ Step 3: FFT Analysis\n",
        "\n",
        "Visualize the frequency domain representation of the MRI.\n",
        "\n",
        "### Understanding the FFT Spectrum\n",
        "\n",
        "The **2D Fourier Transform** decomposes the image into sinusoidal components of different frequencies and orientations.\n",
        "\n",
        "**In the frequency spectrum:**\n",
        "- **Center (DC component)**: Average brightness of the image\n",
        "- **Low frequencies (near center)**: Smooth variations, large structures, background\n",
        "- **High frequencies (edges)**: Sharp transitions, boundaries, fine details\n",
        "- **Tumor boundaries**: Appear as high-frequency components (bright edges)\n",
        "\n",
        "### Course Connection (BME 271D)\n",
        "This extends the 1D Fourier Transform concepts to 2D:\n",
        "- **Spatial domain** ‚Üî **Frequency domain** (via FFT)\n",
        "- **Time** ‚Üí **X and Y position** in images\n",
        "- **Frequency** ‚Üí **Spatial frequency** (cycles per pixel)\n",
        "\n",
        "**Why log scale?** Magnitude spectrum has a huge dynamic range (DC component is much larger than other frequencies). Log transform: `log(1 + magnitude)` compresses the range for better visualization.\n",
        "\n",
        "### What to Look For:\n",
        "- ‚úÖ Bright center = good DC component\n",
        "- ‚úÖ Radial symmetry = isotropic image features\n",
        "- ‚úÖ Cross pattern = horizontal/vertical edges in image\n",
        "- ‚ö†Ô∏è Strong single-frequency lines = periodic noise\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RB3hZ5nakf-p"
      },
      "outputs": [],
      "source": [
        "# FFT Visualization\n",
        "if mri_image is not None:\n",
        "    print('üî¨ Computing FFT spectrum...')\n",
        "    F_shift, mag_spectrum = ts.compute_fft_spectrum(mri_image)\n",
        "    ts.visualize_frequency_spectrum(mri_image, F_shift)\n",
        "    plt.show()\n",
        "    print('‚úÖ FFT analysis complete!')\n",
        "else:\n",
        "    print('‚ùå Please upload an MRI image first!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eorrpLHPkf-q"
      },
      "source": [
        "---\n",
        "## üéØ Step 4: Tumor Detection\n",
        "\n",
        "Run all segmentation methods and visualize results.\n",
        "\n",
        "### Methods Compared\n",
        "\n",
        "#### 1. **Otsu Baseline** (Spatial Domain)\n",
        "- **Method**: Automatic thresholding based on intensity histogram\n",
        "- **Principle**: Maximizes inter-class variance between foreground/background\n",
        "- **Strengths**: Simple, fast, works well on high-contrast images\n",
        "- **Weaknesses**: Struggles with noise, varying illumination, complex textures\n",
        "\n",
        "#### 2. **FFT High-Pass** (Frequency Domain)\n",
        "- **Method**: Removes low frequencies, keeps high frequencies\n",
        "- **Principle**: Tumor boundaries have high-frequency components\n",
        "- **Filter Design**: Circular mask with cutoff radius = 25 pixels\n",
        "- **Strengths**: Emphasizes edges, reduces background influence\n",
        "- **Weaknesses**: Sensitive to noise, may miss uniform tumor regions\n",
        "\n",
        "#### 3. **FFT Band-Pass** (Frequency Domain)\n",
        "- **Method**: Keeps only mid-range frequencies (10-50 pixels)\n",
        "- **Principle**: Tumor texture falls in mid-frequency range\n",
        "- **Filter Design**: Ring-shaped mask (inner radius=10, outer radius=50)\n",
        "- **Strengths**: Captures texture patterns, reduces both noise and background\n",
        "- **Weaknesses**: May miss tumors without distinct texture\n",
        "\n",
        "#### 4. **FFT Combined**\n",
        "- **Method**: Logical OR of High-Pass and Band-Pass results\n",
        "- **Principle**: Combines edge and texture information\n",
        "- **Strengths**: More comprehensive detection\n",
        "- **Weaknesses**: May increase false positives\n",
        "\n",
        "#### 5. **Blob Detection** (Spatial Domain)\n",
        "- **Method**: Finds bright, compact regions with shape constraints\n",
        "- **Principle**: Tumors often appear as bright masses\n",
        "- **Constraints**: Size (100-25% of image), circularity (>0.12), solidity (>0.65)\n",
        "- **Strengths**: Robust to edges, focuses on tumor mass\n",
        "- **Weaknesses**: Misses irregular or ring-shaped tumors\n",
        "\n",
        "#### 6. **Hybrid Combined** (Ensemble)\n",
        "- **Method**: Weighted voting (FFT: 1.5 votes, Blob: 1.0 vote)\n",
        "- **Principle**: Ensemble methods combine multiple approaches\n",
        "- **Threshold**: Requires ‚â•1.0 vote (any single method can trigger)\n",
        "- **Strengths**: Balanced detection, reduces false negatives\n",
        "- **Weaknesses**: More complex, may over-detect\n",
        "\n",
        "---\n",
        "\n",
        "### Confidence Tiers Explained\n",
        "\n",
        "Each detection is scored based on three factors:\n",
        "1. **Size** (30%): Is the detected region a reasonable tumor size (0.4-12% of image)?\n",
        "2. **Shape** (30%): Does it have tumor-like shape (circularity, solidity)?\n",
        "3. **Contrast** (40%): Is it significantly brighter than background?\n",
        "\n",
        "**Confidence Thresholds:**\n",
        "- üî¥ **HIGH (‚â•65%)**: Strong evidence of tumor, urgent follow-up recommended\n",
        "- üü° **MODERATE (35-65%)**: Suspicious finding, additional imaging advised\n",
        "- üü† **LOW (20-35%)**: Possible abnormality, monitor and re-evaluate\n",
        "- üü¢ **NONE (<20%)**: No significant tumor detected\n",
        "\n",
        "### Understanding the Visualization\n",
        "\n",
        "**Green Cross (‚úö)**: Marks tumor center using the **centroid of the largest connected component**. This is more robust than using the brightest pixel or mean of all detected pixels, as it represents the geometric center of the detected tumor mass.\n",
        "\n",
        "**Red Overlay**: Semi-transparent visualization of the detected tumor region (binary mask)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXtEfGu7kf-q"
      },
      "outputs": [],
      "source": [
        "# Run all detection methods\n",
        "if mri_image is not None:\n",
        "    print('üéØ Running tumor detection...')\n",
        "\n",
        "    sensitivity = 0.5\n",
        "\n",
        "    # Get all segmentations\n",
        "    results = {\n",
        "        'Otsu Baseline': otsu_baseline(mri_image),\n",
        "        'FFT High-Pass': fft_highpass(mri_image, sensitivity),\n",
        "        'FFT Band-Pass': fft_bandpass(mri_image, sensitivity),\n",
        "        'FFT Combined': fft_combined(mri_image, sensitivity),\n",
        "        'Blob Detection': blob_detection(mri_image, sensitivity),\n",
        "        'Hybrid Combined': hybrid_combined(mri_image, sensitivity)\n",
        "    }\n",
        "\n",
        "    # Create visualization\n",
        "    fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    # Original image\n",
        "    axes[0].imshow(mri_image, cmap='gray')\n",
        "    axes[0].set_title('Original MRI', fontsize=13, fontweight='bold')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # Each method\n",
        "    for idx, (method_name, seg_mask) in enumerate(results.items(), start=1):\n",
        "        confidence, tier = calculate_confidence(mri_image, seg_mask)\n",
        "        center = get_tumor_center(seg_mask)\n",
        "        area_pct = (seg_mask.sum() / seg_mask.size) * 100\n",
        "\n",
        "        axes[idx].imshow(mri_image, cmap='gray')\n",
        "        axes[idx].imshow(seg_mask, cmap='Reds', alpha=0.5)\n",
        "\n",
        "        # Mark tumor center\n",
        "        if center is not None:\n",
        "            r, c = center\n",
        "            axes[idx].plot(c, r, 'g+', markersize=20, markeredgewidth=3)\n",
        "\n",
        "        # Status text\n",
        "        if tier == 'HIGH':\n",
        "            status = f'üî¥ HIGH\\n{confidence*100:.1f}% | {area_pct:.1f}%'\n",
        "        elif tier == 'MODERATE':\n",
        "            status = f'üü° MODERATE\\n{confidence*100:.1f}% | {area_pct:.1f}%'\n",
        "        elif tier == 'LOW':\n",
        "            status = f'üü† LOW\\n{confidence*100:.1f}% | {area_pct:.1f}%'\n",
        "        else:\n",
        "            status = 'üü¢ Not detected'\n",
        "\n",
        "        axes[idx].set_title(f'{method_name}\\n{status}', fontsize=11, fontweight='bold')\n",
        "        axes[idx].axis('off')\n",
        "\n",
        "    # Hide last empty subplot\n",
        "    axes[7].axis('off')\n",
        "\n",
        "    plt.suptitle('Tumor Segmentation - All Methods', fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print summary table\n",
        "    print('\\n' + '='*80)\n",
        "    print(f'{\"Method\":<20} {\"Confidence\":<15} {\"Tier\":<12} {\"Area %\":<12}')\n",
        "    print('='*80)\n",
        "    for method_name, seg_mask in results.items():\n",
        "        confidence, tier = calculate_confidence(mri_image, seg_mask)\n",
        "        area_pct = (seg_mask.sum() / seg_mask.size) * 100\n",
        "\n",
        "        conf_str = f'{confidence*100:.1f}%'\n",
        "        area_str = f'{area_pct:.2f}%' if tier != 'NONE' else '-'\n",
        "\n",
        "        print(f'{method_name:<20} {conf_str:<15} {tier:<12} {area_str:<12}')\n",
        "    print('='*80)\n",
        "\n",
        "else:\n",
        "    print('‚ùå Please upload an MRI image first!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qke2Rzwikf-q"
      },
      "source": [
        "---\n",
        "## üìä Step 5: Quantitative Evaluation (Only if Ground Truth Provided)\n",
        "\n",
        "Compare all methods using Dice, IoU, and Boundary Accuracy metrics.\n",
        "\n",
        "### Evaluation Metrics Explained\n",
        "\n",
        "#### 1. **Dice Similarity Coefficient (DSC)**\n",
        "**Formula**: `DSC = 2 √ó |A ‚à© B| / (|A| + |B|)`\n",
        "\n",
        "where:\n",
        "- `A` = Predicted tumor mask\n",
        "- `B` = Ground truth mask\n",
        "- `|A ‚à© B|` = Intersection (overlap)\n",
        "- `|A| + |B|` = Sum of areas\n",
        "\n",
        "**Range**: [0, 1] where 1 = perfect overlap\n",
        "\n",
        "**Interpretation:**\n",
        "- **>0.90**: Excellent segmentation\n",
        "- **0.80-0.90**: Good segmentation\n",
        "- **0.70-0.80**: Moderate segmentation\n",
        "- **<0.70**: Poor segmentation\n",
        "\n",
        "**Why use Dice?** Most common metric in medical image segmentation. More intuitive than IoU for clinical interpretation. Gives more weight to overlap than non-overlap.\n",
        "\n",
        "---\n",
        "\n",
        "#### 2. **Intersection over Union (IoU / Jaccard Index)**\n",
        "**Formula**: `IoU = |A ‚à© B| / |A ‚à™ B|`\n",
        "\n",
        "where:\n",
        "- `|A ‚à™ B|` = Union (all detected or true tumor pixels)\n",
        "\n",
        "**Range**: [0, 1] where 1 = perfect overlap\n",
        "\n",
        "**Interpretation:**\n",
        "- **>0.75**: Excellent\n",
        "- **0.50-0.75**: Good\n",
        "- **<0.50**: Poor\n",
        "\n",
        "**Relationship to Dice:**\n",
        "- IoU is **more strict** than Dice\n",
        "- `Dice = 2√óIoU / (1 + IoU)`\n",
        "- IoU penalizes both false positives AND false negatives more heavily\n",
        "\n",
        "---\n",
        "\n",
        "#### 3. **Boundary Accuracy**\n",
        "**Definition**: Percentage of predicted boundary pixels within `tolerance` distance of true boundary\n",
        "\n",
        "**Tolerance**: 2 pixels (~2-4mm in typical MRI)\n",
        "\n",
        "**Range**: [0, 1] where 1 = all boundaries accurate\n",
        "\n",
        "**Clinical Importance**:\n",
        "- **Surgical planning** requires precise tumor margins\n",
        "- **Radiotherapy** needs accurate boundaries to spare healthy tissue\n",
        "- **2-pixel tolerance** is clinically reasonable (sub-5mm accuracy)\n",
        "\n",
        "**Interpretation:**\n",
        "- **>0.90**: Excellent boundary delineation\n",
        "- **0.75-0.90**: Good, acceptable for most clinical uses\n",
        "- **<0.75**: May need manual correction\n",
        "\n",
        "---\n",
        "\n",
        "### Understanding the Bar Plot\n",
        "\n",
        "**Color Coding:**\n",
        "- **Gray**: Otsu Baseline (spatial domain reference)\n",
        "- **Steel Blue**: FFT methods (frequency domain)\n",
        "- **Orange**: Blob Detection (spatial domain)\n",
        "- **Dark Red**: Hybrid Combined (ensemble)\n",
        "\n",
        "**Three Bars Per Method:**\n",
        "- Darker = Dice (most common metric)\n",
        "- Medium = IoU (more strict)\n",
        "- Lighter = Boundary Accuracy (clinical importance)\n",
        "\n",
        "**What to Look For:**\n",
        "- Do FFT methods outperform Otsu?\n",
        "- Which metric shows the biggest improvement?\n",
        "- Is the hybrid method the best overall?\n",
        "\n",
        "---\n",
        "\n",
        "### Project Hypothesis\n",
        "\n",
        "**Hypothesis**: FFT-based methods (High-Pass, Band-Pass) will outperform traditional Otsu thresholding for tumor segmentation due to better handling of:\n",
        "1. Complex texture patterns\n",
        "2. Varying contrast levels\n",
        "3. Edge preservation\n",
        "\n",
        "**Expected Results**: FFT methods should show ~5-20% improvement in Dice coefficient compared to Otsu baseline, especially on high-contrast tumors with clear boundaries.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gK2ksXRkf-q"
      },
      "outputs": [],
      "source": [
        "# Quantitative evaluation\n",
        "if mri_image is not None and ground_truth_mask is not None:\n",
        "    print('üìä Calculating quantitative metrics...')\n",
        "\n",
        "    # Evaluate all methods\n",
        "    metrics_df, method_masks = evaluate_all_methods(mri_image, ground_truth_mask, sensitivity=0.5)\n",
        "\n",
        "    # Display table\n",
        "    print('\\n' + '='*80)\n",
        "    print('QUANTITATIVE EVALUATION RESULTS')\n",
        "    print('='*80)\n",
        "    print(metrics_df.to_string(index=False))\n",
        "    print('='*80)\n",
        "\n",
        "    # Create bar plot comparison\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(14, 6))\n",
        "\n",
        "    methods = metrics_df['Method'].values\n",
        "    x = np.arange(len(methods))\n",
        "    width = 0.25\n",
        "\n",
        "    # Colors: Otsu in gray, FFT methods in blue, Hybrid in red\n",
        "    colors = ['gray', 'steelblue', 'steelblue', 'steelblue', 'orange', 'darkred']\n",
        "\n",
        "    # Plot bars for each metric\n",
        "    bars1 = ax.bar(x - width, metrics_df['Dice'], width, label='Dice Coefficient', color=colors, alpha=0.8)\n",
        "    bars2 = ax.bar(x, metrics_df['IoU'], width, label='IoU Score', color=colors, alpha=0.6)\n",
        "    bars3 = ax.bar(x + width, metrics_df['Boundary Accuracy'], width, label='Boundary Accuracy', color=colors, alpha=0.4)\n",
        "\n",
        "    # Add value labels on bars\n",
        "    def add_value_labels(bars):\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                   f'{height:.3f}',\n",
        "                   ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "    add_value_labels(bars1)\n",
        "    add_value_labels(bars2)\n",
        "    add_value_labels(bars3)\n",
        "\n",
        "    ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
        "    ax.set_title('Segmentation Performance Comparison\\n(Higher is Better)', fontsize=14, fontweight='bold')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(methods, rotation=15, ha='right')\n",
        "    ax.legend(loc='upper left', fontsize=10)\n",
        "    ax.set_ylim(0, 1.1)\n",
        "    ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Analysis\n",
        "    print('\\nüìà ANALYSIS:')\n",
        "    best_dice = metrics_df.loc[metrics_df['Dice'].idxmax()]\n",
        "    best_iou = metrics_df.loc[metrics_df['IoU'].idxmax()]\n",
        "    best_boundary = metrics_df.loc[metrics_df['Boundary Accuracy'].idxmax()]\n",
        "\n",
        "    print(f'   Best Dice: {best_dice[\"Method\"]} ({best_dice[\"Dice\"]:.3f})')\n",
        "    print(f'   Best IoU: {best_iou[\"Method\"]} ({best_iou[\"IoU\"]:.3f})')\n",
        "    print(f'   Best Boundary: {best_boundary[\"Method\"]} ({best_boundary[\"Boundary Accuracy\"]:.3f})')\n",
        "\n",
        "    # Compare to Otsu baseline\n",
        "    otsu_dice = metrics_df[metrics_df['Method'] == 'Otsu Baseline']['Dice'].values[0]\n",
        "    print(f'\\n   Otsu Baseline Dice: {otsu_dice:.3f}')\n",
        "\n",
        "    improvements = []\n",
        "    for _, row in metrics_df.iterrows():\n",
        "        if row['Method'] != 'Otsu Baseline' and row['Dice'] > otsu_dice:\n",
        "            improvement = ((row['Dice'] - otsu_dice) / otsu_dice) * 100\n",
        "            improvements.append(f\"   - {row['Method']}: +{improvement:.1f}% improvement\")\n",
        "\n",
        "    if improvements:\n",
        "        print('\\n   Methods outperforming Otsu:')\n",
        "        for imp in improvements:\n",
        "            print(imp)\n",
        "    else:\n",
        "        print('\\n   ‚ö†Ô∏è  No method significantly outperformed Otsu baseline')\n",
        "\n",
        "elif mri_image is not None:\n",
        "    print('\\n‚ÑπÔ∏è  Skipping quantitative evaluation (no ground truth mask provided)')\n",
        "else:\n",
        "    print('‚ùå Please upload an MRI image first!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DefVAEWqkf-q"
      },
      "source": [
        "---\n",
        "## üè• Step 6: Final Clinical Report\n",
        "\n",
        "Summary report with the Hybrid Combined method (recommended).\n",
        "\n",
        "### Why Hybrid Combined?\n",
        "\n",
        "The **Hybrid Combined** method is our recommended approach because it:\n",
        "- Combines frequency-domain analysis (FFT) with spatial-domain blob detection\n",
        "- Uses weighted voting to balance sensitivity and specificity\n",
        "- Reduces false negatives (missing tumors) while controlling false positives\n",
        "- Provides robust detection across various tumor types and imaging conditions\n",
        "\n",
        "### Clinical Decision Support\n",
        "\n",
        "This report translates quantitative metrics into **actionable clinical recommendations**:\n",
        "\n",
        "**üî¥ HIGH CONFIDENCE (‚â•65%)**\n",
        "- **Interpretation**: Strong evidence of tumor presence\n",
        "- **Recommendation**: Urgent follow-up with neurology/neurosurgery\n",
        "- **Next steps**: Confirmatory imaging, biopsy planning, treatment consultation\n",
        "\n",
        "**üü° MODERATE CONFIDENCE (35-65%)**\n",
        "- **Interpretation**: Suspicious finding requiring further investigation\n",
        "- **Recommendation**: Additional imaging (contrast-enhanced MRI, MR spectroscopy)\n",
        "- **Next steps**: Repeat scan in 3-6 months, compare with previous studies\n",
        "\n",
        "**üü† LOW CONFIDENCE (20-35%)**\n",
        "- **Interpretation**: Possible abnormality, uncertain significance\n",
        "- **Recommendation**: Monitor with routine follow-up\n",
        "- **Next steps**: Correlate with clinical symptoms, consider repeat imaging in 6-12 months\n",
        "\n",
        "**üü¢ NO TUMOR DETECTED (<20%)**\n",
        "- **Interpretation**: No significant abnormality detected\n",
        "- **Recommendation**: No immediate action required\n",
        "- **Next steps**: Routine screening based on patient risk factors\n",
        "\n",
        "### Important Disclaimers\n",
        "\n",
        "‚ö†Ô∏è **This is a demonstration tool for educational purposes (BME 271D Final Project)**  \n",
        "‚ö†Ô∏è **Not validated for clinical use** - would require FDA clearance  \n",
        "‚ö†Ô∏è **Not a replacement for radiologist expertise** - intended to assist, not replace  \n",
        "‚ö†Ô∏è **Performance varies** based on image quality, tumor type, and imaging parameters\n",
        "\n",
        "### Real-World Deployment Considerations\n",
        "\n",
        "To use this system clinically, we would need:\n",
        "1. **Extensive validation** on diverse patient datasets\n",
        "2. **Performance benchmarking** against expert radiologists\n",
        "3. **Sensitivity/specificity optimization** for specific clinical workflows\n",
        "4. **Integration** with PACS (Picture Archiving and Communication System)\n",
        "5. **Regulatory approval** (FDA, CE marking)\n",
        "6. **Continuous monitoring** of real-world performance\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbrg7u29kf-q"
      },
      "outputs": [],
      "source": [
        "# Final clinical report\n",
        "if mri_image is not None and 'results' in dir():\n",
        "    print('üè• Generating final clinical report...')\n",
        "\n",
        "    final_mask = results['Hybrid Combined']\n",
        "    confidence, tier = calculate_confidence(mri_image, final_mask)\n",
        "    center = get_tumor_center(final_mask)\n",
        "    area_pct = (final_mask.sum() / final_mask.size) * 100\n",
        "\n",
        "    # Visualization\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
        "\n",
        "    # Original\n",
        "    axes[0].imshow(mri_image, cmap='gray')\n",
        "    axes[0].set_title('Original MRI', fontsize=14, fontweight='bold')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # Detection\n",
        "    axes[1].imshow(mri_image, cmap='gray')\n",
        "    if tier != 'NONE':\n",
        "        axes[1].imshow(final_mask, cmap='Reds', alpha=0.5)\n",
        "        if center is not None:\n",
        "            r, c = center\n",
        "            axes[1].plot(c, r, 'g+', markersize=30, markeredgewidth=4)\n",
        "    axes[1].set_title('Hybrid Detection Result', fontsize=14, fontweight='bold')\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    # Report\n",
        "    axes[2].axis('off')\n",
        "\n",
        "    if tier == 'HIGH':\n",
        "        status = '‚ö†Ô∏è TUMOR DETECTED'\n",
        "        verdict = 'üî¥ HIGH CONFIDENCE'\n",
        "        recommendation = 'Urgent follow-up recommended'\n",
        "    elif tier == 'MODERATE':\n",
        "        status = '‚ùì SUSPICIOUS FINDING'\n",
        "        verdict = 'üü° MODERATE CONFIDENCE'\n",
        "        recommendation = 'Additional imaging advised'\n",
        "    elif tier == 'LOW':\n",
        "        status = '‚ùì POSSIBLE ABNORMALITY'\n",
        "        verdict = 'üü† LOW CONFIDENCE'\n",
        "        recommendation = 'Monitor and re-evaluate'\n",
        "    else:\n",
        "        status = '‚úÖ NO TUMOR DETECTED'\n",
        "        verdict = 'üü¢ Normal Brain'\n",
        "        recommendation = 'No immediate action required'\n",
        "\n",
        "    report_text = f\"\"\"\n",
        "\n",
        "    {status}\n",
        "\n",
        "    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "\n",
        "    Confidence: {confidence*100:.1f}%\n",
        "    Affected Area: {area_pct:.2f}%\n",
        "\n",
        "    Method: Hybrid Ensemble\n",
        "    (FFT + Blob Detection)\n",
        "\n",
        "    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "\n",
        "    {verdict}\n",
        "\n",
        "    {recommendation}\n",
        "    \"\"\"\n",
        "\n",
        "    axes[2].text(0.05, 0.5, report_text, fontsize=12, verticalalignment='center',\n",
        "                fontfamily='monospace',\n",
        "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
        "    axes[2].set_title('Clinical Report', fontsize=14, fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print('\\n' + '='*70)\n",
        "    print(f'  {verdict}')\n",
        "    print('='*70)\n",
        "\n",
        "else:\n",
        "    print('‚ùå Please run detection first!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk3ucf12kf-r"
      },
      "source": [
        "---\n",
        "## üéì Conclusion & Key Takeaways\n",
        "\n",
        "### What We Demonstrated\n",
        "\n",
        "This project successfully applied **Signals & Systems** concepts from BME 271D to a real biomedical engineering problem:\n",
        "\n",
        "1. **2D Fourier Transform**: Extended 1D FFT to medical images\n",
        "2. **Filter Design**: Implemented high-pass and band-pass filters in frequency domain\n",
        "3. **System Analysis**: Compared frequency-domain vs. spatial-domain methods\n",
        "4. **Performance Evaluation**: Used quantitative metrics (Dice, IoU, Boundary Accuracy)\n",
        "5. **Ensemble Methods**: Combined multiple approaches for robust detection\n",
        "\n",
        "### Key Findings\n",
        "\n",
        "**Strengths of FFT-Based Methods:**\n",
        "- ‚úÖ Better edge detection (high-pass filtering)\n",
        "- ‚úÖ Texture analysis capabilities (band-pass filtering)\n",
        "- ‚úÖ Reduced sensitivity to global intensity variations\n",
        "- ‚úÖ Complementary information to spatial methods\n",
        "\n",
        "**Limitations:**\n",
        "- ‚ö†Ô∏è Performance depends on tumor contrast\n",
        "- ‚ö†Ô∏è Sensitive to image quality and noise\n",
        "- ‚ö†Ô∏è Requires parameter tuning (cutoff frequencies)\n",
        "- ‚ö†Ô∏è Computational cost of FFT operations\n",
        "\n",
        "### Clinical Relevance\n",
        "\n",
        "**Potential Applications:**\n",
        "- Computer-aided detection (CAD) systems\n",
        "- Radiologist decision support\n",
        "- Treatment planning assistance\n",
        "- Automated screening workflows\n",
        "\n",
        "**Impact:**\n",
        "- Reduces radiologist workload\n",
        "- Standardizes segmentation quality\n",
        "- Enables faster diagnosis\n",
        "- Improves patient outcomes through earlier detection\n",
        "\n",
        "### Future Improvements\n",
        "\n",
        "1. **Adaptive Filtering**: Automatically adjust parameters based on image characteristics\n",
        "2. **3D Analysis**: Process entire MRI volumes instead of 2D slices\n",
        "3. **Multi-Modal Fusion**: Combine T1, T2, FLAIR sequences\n",
        "4. **Deep Learning Integration**: Use FFT features as input to neural networks\n",
        "5. **Real-Time Performance**: GPU acceleration for clinical workflow\n",
        "6. **Uncertainty Quantification**: Provide confidence intervals for measurements\n",
        "\n",
        "### Course Connection\n",
        "\n",
        "This project demonstrates how fundamental signal processing concepts from BME 271D apply to real-world biomedical problems:\n",
        "\n",
        "- **Fourier Transform** ‚Üí Analyzing medical images in frequency domain\n",
        "- **Filter Design** ‚Üí Enhancing tumor features\n",
        "- **System Analysis** ‚Üí Comparing different detection methods\n",
        "- **Performance Metrics** ‚Üí Quantifying segmentation quality\n",
        "\n",
        "### Acknowledgments\n",
        "\n",
        "- BME 271D teaching staff for course content\n",
        "- Duke University BME Department\n",
        "- Open-source medical imaging datasets\n",
        "- Python scientific computing community\n",
        "\n",
        "---\n",
        "\n",
        "## üìö References\n",
        "\n",
        "1. Otsu, N. (1979). \"A threshold selection method from gray-level histograms.\" *IEEE Trans. Systems, Man, and Cybernetics*, 9(1), 62-66.\n",
        "\n",
        "2. Dice, L.R. (1945). \"Measures of the amount of ecologic association between species.\" *Ecology*, 26(3), 297-302.\n",
        "\n",
        "3. Menze, B.H., et al. (2015). \"The Multimodal Brain Tumor Image Segmentation Benchmark (BRATS).\" *IEEE Transactions on Medical Imaging*, 34(10), 1993-2024.\n",
        "\n",
        "4. Gonzalez, R.C., & Woods, R.E. (2018). *Digital Image Processing* (4th ed.). Pearson.\n",
        "\n",
        "5. The Cancer Imaging Archive (TCIA): https://www.cancerimagingarchive.net/\n",
        "\n",
        "---\n",
        "\n",
        "*BME 271D: Signals and Systems in Biomedical Engineering*  \n",
        "*Duke University, Fall 2024*  \n",
        "*Team: Ege √ñzemek, Max Bazan, Sasha Nikiforov*\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}